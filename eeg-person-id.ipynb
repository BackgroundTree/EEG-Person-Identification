{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13832122,"sourceType":"datasetVersion","datasetId":8809302}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EEG Person Identification Pipeline\n\nThis notebook implements a data processing and modeling pipeline for the **EEG Motor Movement/Imagery Dataset**. \n\nThe pipeline performs the following steps:\n1.  **Data Loading**: Reads raw EDF files using MNE.\n2.  **Preprocessing**: Applies bandpass filtering and channel selection.\n3.  **Feature Extraction**: Segments signals into epochs and converts them into spectrograms (STFT).\n4.  **Dataset Creation**: Splits data into Training (Session A) and Testing (Session B) sets and saves them as `.npy` arrays.\n5.  **Modeling**: Defines and trains a PyTorch model for person identification.","metadata":{}},{"cell_type":"code","source":"from __future__ import annotations\nimport json\nimport os\nfrom dataclasses import asdict, dataclass\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Tuple\n\n# Core Data & Plotting\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# Signal Processing & Domain Specific\nimport mne\nfrom scipy.signal import stft\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\n# Deep Learning (PyTorch)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nprint(f\"MNE version: {mne.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"PyTorch version: {torch.__version__}\")\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:49:34.505383Z","iopub.execute_input":"2025-12-16T05:49:34.509954Z","iopub.status.idle":"2025-12-16T05:49:43.220010Z","shell.execute_reply.started":"2025-12-16T05:49:34.509715Z","shell.execute_reply":"2025-12-16T05:49:43.218785Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Global Configuration\n\nThe `Config` class centralizes all pipeline parameters. This includes:\n* **File Paths**: Locations for input data and processed output.\n* **Signal Parameters**: Sample rate (160 Hz), bandpass frequencies (1-40 Hz).\n* **STFT Settings**: Window size and overlap for spectrogram generation.\n* **Execution Limits**: Options to limit the number of subjects (`subjects_limit`) or runs for faster testing.","metadata":{}},{"cell_type":"code","source":"#changes values to control how much data is loaded, exact STFT windows, and where processed files are written.\n\nProject_Root = Path.cwd()\nData_Root = Path(\"/kaggle/input/eeg-motor-movementimagery-dataset/files\") #data store location, change as needed\nProcessed_Root = Path(\"/kaggle/working/processed\") #processed data output location, change as desired\n\n@dataclass\nclass Config:\n    data_root: Path = Data_Root\n    processed_root: Path = Processed_Root\n    subjects_limit: int | None = 15 # set to None to use all 109 subjects\n    runs_per_subject: int | None = None  # each subject has 14 runs (7 per session)\n    window_seconds: float = 2.0\n    step_seconds: float = 0.5\n    raw_sample_rate: int = 160  # Hz per PhysioNet documentation\n    bandpass_low: float = 1.0\n    bandpass_high: float = 40.0\n    stft_nperseg: int = 128\n    stft_noverlap: int = 96\n    max_epochs_per_run: int | None = None\n    max_abs_uV: float = 300.0  # reject epochs with larger amplitudes\n    target_channels: List[str] | None = None  # None -> keep whatever is common across runs\n    random_state: int = 67\n\n    @property\n    def output_arrays_dir(self) -> Path:\n        return self.processed_root / \"metadata\"\n\n    @property\n    def metadata_dir(self) -> Path:\n        return self.processed_root / \"metadata\"\n\nconfig = Config()\n\nenv_override = {\n    \"subject_limit\": os.environ.get(\"EEG_SUBJECTS_LIMIT\"),\n    \"runs_per_subject\": os.environ.get(\"EEG_RUNS_PER_SUBJECT\"),\n    \"max_epoch_per_run\": os.environ.get(\"EEG_MAX_EPOCHS_PER_RUN\"),\n}\nfor key, value in env_override.items():\n    if value is not None:\n        casted = None if value.lower() == \"none\" else int(value)\n        setattr(config, key, casted)\n\nconfig.processed_root.mkdir(parents=True, exist_ok=True)\nconfig.output_arrays_dir.mkdir(parents=True, exist_ok=True)\nconfig.metadata_dir.mkdir(parents=True, exist_ok=True)\n\nprint(json.dumps({k: str(v) if isinstance(v, Path) else v for k, v in asdict(config).items()}, indent= 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:49:43.221652Z","iopub.execute_input":"2025-12-16T05:49:43.222345Z","iopub.status.idle":"2025-12-16T05:49:43.236889Z","shell.execute_reply.started":"2025-12-16T05:49:43.222317Z","shell.execute_reply":"2025-12-16T05:49:43.235173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Data Discovery\n\nThese helper functions verify the input directory structure and list available subjects and runs to ensure the dataset is accessible before processing.","metadata":{}},{"cell_type":"code","source":"def list_subjects(data_root: Path) -> List[Path]:\n    return sorted([p for p in data_root.glob(\"S*\") if p.is_dir()])\n\ndef list_runs_for_subject(subject_dir: Path) -> List[Path]:\n    return sorted(subject_dir.glob(\"*.edf\"))\n\ndef preview_df(data_root: Path, max_subjects: int = 5) -> pd.DataFrame:\n    rows = []\n    for subject_dir in list_subjects(data_root)[:max_subjects]:\n        runs = list_runs_for_subject(subject_dir)\n        rows.append(\n            {\n                \"subject\": subject_dir.name,\n                \"num_runs\": len(runs),\n                \"first_run\": runs[0].name if runs else None,\n                \"last_run\": runs[-1].name if runs else None,\n            }\n        )\n    return pd.DataFrame(rows)\n\npreview_df(config.data_root)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:49:43.237842Z","iopub.execute_input":"2025-12-16T05:49:43.238131Z","iopub.status.idle":"2025-12-16T05:49:43.497241Z","shell.execute_reply.started":"2025-12-16T05:49:43.238106Z","shell.execute_reply":"2025-12-16T05:49:43.496283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Signal Processing Utilities\n\nWe define core functions to handle the raw EEG data:\n* `load_raw_run`: Loads `.edf` files.\n* `bandpass_filter`: Applies FIR bandpass filtering (1-40 Hz).\n* `make_epochs`: Segments continuous data into fixed-length windows.\n* `epoch_to_spectrogram`: Converts time-domain epochs into frequency-domain spectrograms using Short-Time Fourier Transform (STFT).","metadata":{}},{"cell_type":"code","source":"#smol functions for filtering,epoching, and spectrogram gen\n\ndef load_raw_run(edf_path: Path) -> mne.io.BaseRaw:\n    raw = mne.io.read_raw_edf(edf_path, preload = True, verbose = \"ERROR\")\n    raw.set_montage(\"standard_1020\", on_missing = \"ignore\")\n    return raw\n\ndef prep_channels(raw: mne.io.BaseRaw, target_channels: List[str] | None) -> mne.io.BaseRaw:\n    if target_channels is None:\n        return raw\n    present_channels = [ch for ch in target_channels if ch in raw.ch_names]\n    if not present_channels:\n        raise ValueError(\"None of the requested channels were found in this rec.\")\n    return raw.pick(present_channels, verbose = \"ERROR\")\n\ndef bandpass_filter(raw: mne.io.BaseRaw, low: float, high: float) -> mne.io.BaseRaw:\n    return raw.filter(l_freq = low, h_freq = high, fir_design = \"firwin\", verbose = \"ERROR\")\n\ndef make_epochs(raw: mne.io.BaseRaw, config: Config) -> mne.Epochs:\n    events = mne.make_fixed_length_events(\n        raw,\n        start = 0,\n        stop = None,\n        duration = config.step_seconds,\n        overlap = 0.0\n    )\n    reject = dict(eeg=config.max_abs_uV * 1e-6)\n    epochs = mne.Epochs(\n        raw,\n        events,\n        event_id = {\"segment\": 1},\n        tmin = 0.0,\n        tmax = config.window_seconds,\n        baseline = None,\n        preload = True,\n        reject = reject,\n        verbose = \"ERROR\",\n    )\n    if config.max_epochs_per_run:\n        epochs = epochs[: config.max_epochs_per_run]\n    return epochs\n\ndef epoch_to_spectrogram(\n    epoch_data: np.ndarray,\n    sfreq: int,\n    nperseg: int,\n    noverlap: int,\n) -> np.ndarray:\n    \"\"\"Convert a (channels, samples) array to (freq, time, channels) spectrogram.\"\"\"\n\n    spectrograms = []\n    for channel_trace in epoch_data:\n        freqs, times, Zxx = stft(\n            channel_trace,\n            fs = sfreq,\n            nperseg = nperseg,\n            noverlap = noverlap,\n            padded = False,\n            boundary = None,\n        )\n        spectrograms.append(np.abs(Zxx))\n    spec = np.stack(spectrograms, axis = -1) # (Freq, time, ch)\n    spec = np.log1p(spec)\n    spec = (spec - spec.mean()) / (spec.std() + 1e-8)\n    return spec.astype(np.float32)\n\ndef map_run_to_sesh(run_path: Path) -> str:\n    run_number = int(run_path.stem[-2:]) #R01 thru R014\n    return \"Session_A\" if run_number <= 7 else \"Session_B\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:49:43.499137Z","iopub.execute_input":"2025-12-16T05:49:43.499403Z","iopub.status.idle":"2025-12-16T05:49:43.512669Z","shell.execute_reply.started":"2025-12-16T05:49:43.499381Z","shell.execute_reply":"2025-12-16T05:49:43.511149Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Pipeline Logic (`build_df`)\n\nThe `build_df` function drives the processing pipeline:\n1.  Iterates through subjects and runs.\n2.  Applies preprocessing and feature extraction.\n3.  Splits data based on session (Session A → Train, Session B → Test).\n4.  Aggregates processed spectrograms into `.npy` arrays and saves metadata.","metadata":{}},{"cell_type":"code","source":"def build_df(config: Config) -> Dict[str, Path]:\n    subjects = list_subjects(config.data_root)\n    if config.subjects_limit:\n        subjects = subjects[: config.subjects_limit]\n\n    label_encoder = LabelEncoder()\n    label_encoder.fit([subj.name for subj in subjects])\n\n    train_specs, train_labels = [], []\n    test_specs, test_labels = [], []\n    metadata_rows = []\n\n    for subject_dir in tqdm(subjects, desc=\"Subjects\"):\n        runs = list_runs_for_subject(subject_dir)\n        if config.runs_per_subject:\n            runs = runs[: config.runs_per_subject]\n\n        for run_path in runs:\n            session = map_run_to_sesh(run_path)\n            raw = load_raw_run(run_path)\n            raw = prep_channels(raw, config.target_channels)\n            raw = bandpass_filter(raw, config.bandpass_low, config.bandpass_high)\n            if int(raw.info[\"sfreq\"]) != config.raw_sample_rate:\n                raw.resample(config.raw_sample_rate)\n\n            epochs = make_epochs(raw, config)\n                        # Check for empty epochs and skip the run if necessary\n            if not len(epochs):\n                print(f\"!!! WARNING: No epochs found for {run_path.name}. Skipping run.\")\n                continue  # Skip the rest of the inner loop and move to the next run.\n\n            epoch_arr = epochs.get_data() #(n epochs, ch, samples)\n\n            for epoch_idx, epoch_data in enumerate(epoch_arr):\n                spec = epoch_to_spectrogram(\n                    epoch_data,\n                    sfreq = config.raw_sample_rate,\n                    nperseg = config.stft_nperseg,\n                    noverlap = config.stft_noverlap,\n                )\n                label = label_encoder.transform([subject_dir.name])[0]\n                record = {\n                    \"subject\": subject_dir.name,\n                    \"run\": run_path.name,\n                    \"session\": session,\n                    \"epoch_index\": epoch_idx,\n                    \"label\": int(label),\n                }\n                metadata_rows.append(record)\n\n                if session == \"Session_A\":\n                    train_specs.append(spec)\n                    train_labels.append(label)\n                else:\n                    test_specs.append(spec)\n                    test_labels.append(label)\n\n    X_train = np.stack(train_specs)\n    y_train = np.array(train_labels)\n    X_test = np.stack(test_specs)\n    y_test = np.array(test_labels)\n\n    np.save(config.output_arrays_dir / \"X_train.npy\", X_train)\n    np.save(config.output_arrays_dir / \"y_train.npy\", y_train)\n    np.save(config.output_arrays_dir / \"X_test.npy\", X_test)\n    np.save(config.output_arrays_dir / \"y_test.npy\", y_test)\n\n    metadata_df = pd.DataFrame(metadata_rows)\n    metadata_path = config.metadata_dir / \"epochs_metadata.csv\"\n    metadata_df.to_csv(metadata_path, index = False)\n\n    label_mapping = dict(enumerate(label_encoder.classes_))\n    with open(config.metadata_dir / \"label_mapping.json\", \"w\") as fp:\n        json.dump(\n            {k: str(v) if isinstance(v, Path) else v for k, v in asdict(config).items()}, \n            fp,\n            indent = 2,\n        )\n\n    return {\n        \"X_train\": config.output_arrays_dir / \"X_train.npy\",\n        \"y_train\": config.output_arrays_dir / \"y_train.npy\",\n        \"X_test\": config.output_arrays_dir / \"X_test.npy\",\n        \"y_test\": config.output_arrays_dir / \"y_test.npy\",\n        \"metadata\": metadata_path,\n        \"label_mapping\": config.metadata_dir / \"label_mapping.json\"\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:49:43.514153Z","iopub.execute_input":"2025-12-16T05:49:43.514477Z","iopub.status.idle":"2025-12-16T05:49:43.540916Z","shell.execute_reply.started":"2025-12-16T05:49:43.514443Z","shell.execute_reply":"2025-12-16T05:49:43.539547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Execution\n\nSet `RUN_PIPELINE = True` to execute the heavy processing. This may take some time depending on the number of subjects configured.","metadata":{}},{"cell_type":"code","source":"RUN_PIPELINE = True\n\nif RUN_PIPELINE:\n    print(\"Starting data pipeline build..\")\n    output_paths = build_df(config)\n    print(\"Done !!!\")\n    output_paths\nelse:\n    print(\"Set RUN_PIPELINE = True !!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:49:43.542265Z","iopub.execute_input":"2025-12-16T05:49:43.542622Z","iopub.status.idle":"2025-12-16T05:54:42.579070Z","shell.execute_reply.started":"2025-12-16T05:49:43.542588Z","shell.execute_reply":"2025-12-16T05:54:42.577205Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Output Verification\n\nAfter processing, we verify that the output files (`X_train.npy`, etc.) exist and inspect their shapes to ensure data consistency.","metadata":{}},{"cell_type":"code","source":"#sanity check :3\ndef descArrays(config: Config) -> pd.DataFrame:\n    paths ={\n        \"X_train\": config.output_arrays_dir / \"X_train.npy\",\n        \"y_train\": config.output_arrays_dir / \"y_train.npy\",\n        \"X_test\": config.output_arrays_dir / \"X_test.npy\",\n        \"y_test\": config.output_arrays_dir / \"y_test.npy\",\n    }\n    rows = []\n    for name, path in paths.items():\n        if not path.exists():\n            rows.append({\"name\": name, \"status\": \"missing\"})\n            continue\n\n        arr = np.load(path, mmap_mode=\"r\")\n        rows.append(\n            {\n                \"name\": name,\n                \"status\": \"ok\",\n                \"dtype\": str(arr.dtype),\n                \"shape\": arr.shape\n            }\n        )\n    return pd.DataFrame(rows)\n\ndescArrays(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:54:42.581494Z","iopub.execute_input":"2025-12-16T05:54:42.582150Z","iopub.status.idle":"2025-12-16T05:54:42.608951Z","shell.execute_reply.started":"2025-12-16T05:54:42.582114Z","shell.execute_reply":"2025-12-16T05:54:42.607812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Project_Root = Path.cwd()\nProcessed_Root = Path(\"/kaggle/working/processed\")\nModels_Root = Project_Root / \"models\"\nReports_Root = Project_Root / \"reports\"\n\n@dataclass\nclass TrainConfig:\n    processed_root: Path = Processed_Root\n    models_root: Path = Models_Root\n    reports_root: Path = Reports_Root\n    batch_size: int = 32\n    epochs: int = 30\n    learning_rate: float = 1e-3\n    validation_split: float = 0.1\n    dropout_rate: float = 0.3\n    lstm_units: int = 128\n    conv_filters: tuple[int, ...] = (32, 64, 128)\n    patience: int = 10\n\n    @property\n    def numpy_dir(self) -> Path:\n        return self.processed_root / \"metadata\"\n\n    @property\n    def metadata_dir(self) -> Path:\n        return self.processed_root / \"metadata\"\n\nTconfig = TrainConfig()\n\ntrain_overrides = {\n    \"batch_size\": os.environ.get(\"EEG_BATCH_SIZE\"),\n    \"epochs\": os.environ.get(\"EEG_EPOCHS\"),\n    \"learning_rate\": os.environ.get(\"EEG_LR\"),\n}\n\nfor key, value in train_overrides.items():\n    if value is not None:\n        casted = float(value) if key == \"learning_rate\" else int(value)\n        setattr(Tconfig, key, casted)\n\nTconfig.models_root.mkdir(parents = True, exist_ok = True)\nTconfig.reports_root.mkdir(parents = True, exist_ok = True)\n\nprint(json.dumps({k: str(v) if isinstance(v, Path) else v for k, v in asdict(Tconfig).items()}, indent = 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:54:42.610464Z","iopub.execute_input":"2025-12-16T05:54:42.610938Z","iopub.status.idle":"2025-12-16T05:54:42.625180Z","shell.execute_reply.started":"2025-12-16T05:54:42.610904Z","shell.execute_reply":"2025-12-16T05:54:42.623941Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Data Loading & Dataset Definition\n\nWe load the preprocessed `.npy` files and wrap them in a custom PyTorch `Dataset`.\n* **`SpectrogramDataset`**: Handles the conversion of NumPy arrays to PyTorch tensors. It also permutes the dimensions to `(Batch, Channels, Height, Width)` as required by 2D CNN layers.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport numpy as np\n\nclass EEGDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n        # Permute (N, Freq, Time, Ch) -> (N, Ch, Freq, Time) to match PyTorch Conv2d expectations\n        self.X = self.X.permute(0, 3, 1, 2)\n\n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ndef load_data_safe(config: TrainConfig):\n    # 1. Load Arrays using the config paths\n    try:\n        X_train = np.load(config.numpy_dir / \"X_train.npy\")\n        y_train = np.load(config.numpy_dir / \"y_train.npy\")\n        X_test = np.load(config.numpy_dir / \"X_test.npy\")\n        y_test = np.load(config.numpy_dir / \"y_test.npy\")\n    except FileNotFoundError:\n        print(\"Data files not found. Please ensure RUN_PIPELINE=True and has completed successfully.\")\n        return None, None, 0, (0,0,0)\n    \n\n    le = LabelEncoder()\n    # Fit on ALL labels (train + test) to ensure consistency\n    all_labels = np.concatenate([y_train, y_test])\n    le.fit(all_labels)\n    \n    y_train = le.transform(y_train)\n    y_test = le.transform(y_test)\n    \n    num_classes = len(le.classes_)\n    print(f\"Labels Re-indexed. Mapped {len(le.classes_)} unique subjects to range 0-{num_classes-1}.\")\n    \n    train_ds = EEGDataset(X_train, y_train)\n    test_ds = EEGDataset(X_test, y_test)\n    \n    # Get input dimensions from the first sample\n    sample_x, _ = train_ds[0] # Shape: (Ch, Freq, Time)\n    input_dims = sample_x.shape\n    \n    return train_ds, test_ds, num_classes, input_dims\n\n# Load Data\ntrain_dataset, test_dataset, num_classes, input_dims = load_data_safe(Tconfig)\n\nif train_dataset is not None:\n    # Extract dimensions for the model\n    num_ch, freq_bins, time_bins = input_dims\n    print(f\"Model Input: {num_ch} Channels, {freq_bins} Freq, {time_bins} Time\")\n    print(f\"Output Classes: {num_classes}\")\n\n    # Create DataLoaders\n    # Split training set into Train (90%) and Validation (10%)\n    val_size = int(Tconfig.validation_split * len(train_dataset))\n    train_size = len(train_dataset) - val_size\n    train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n\n    # Define Loaders\n    dtrain = DataLoader(train_subset, batch_size=Tconfig.batch_size, shuffle=True)\n    dval = DataLoader(val_subset, batch_size=Tconfig.batch_size, shuffle=False)\n    dtest = DataLoader(test_dataset, batch_size=Tconfig.batch_size, shuffle=False)\n    \n    print(f\"DataLoaders Created: Train={len(dtrain)} batches, Val={len(dval)} batches, Test={len(dtest)} batches\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:54:42.626413Z","iopub.execute_input":"2025-12-16T05:54:42.626952Z","iopub.status.idle":"2025-12-16T05:54:50.862122Z","shell.execute_reply.started":"2025-12-16T05:54:42.626900Z","shell.execute_reply":"2025-12-16T05:54:50.861188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Hybrid Model Architecture (CNN-BiLSTM)\n\nWe implement a hybrid architecture designed for Spatio-Temporal feature extraction:\n1.  **CNN Encoder**: A stack of Convolutional blocks extracts spatial and frequency features from the spectrograms. We use *asymmetric pooling* to reduce frequency dimensions while preserving the time axis.\n2.  **BiLSTM**: A Bidirectional LSTM processes the sequence of CNN features to capture temporal dynamics.\n3.  **Classifier**: A dense layer maps the final LSTM state to the person identity.","metadata":{}},{"cell_type":"code","source":"class CNNDropout(nn.Module):\n    def __init__(self, filters: int, dropout_rate: float):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels=filters[0], out_channels=filters[1], kernel_size=(3, 3), padding=\"same\"),\n            nn.BatchNorm2d(filters[1]),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n            nn.Dropout(dropout_rate)\n        )\n    \n    def forward(self, x):\n        return self.conv(x)\n\nclass CNNBiLSTM(nn.Module):\n    def __init__(self, freq_bins: int, time_bins: int, channels: int, num_classes: int, Tconfig: TrainConfig):\n        super().__init__()\n        self.freq_bins = freq_bins\n        self.time_bins = time_bins\n        \n        # 1. Convolutional Tower \n        conv_layers = []\n        in_channels = channels\n        \n        for filters in Tconfig.conv_filters: \n            conv_layers.append(nn.Conv2d(in_channels, filters, kernel_size=(3, 3), padding=1))\n            conv_layers.append(nn.BatchNorm2d(filters))\n            conv_layers.append(nn.ReLU())\n            \n            # FIX: Asymmetric Pooling\n            # Pool Frequency (Height) by 2, but keep Time (Width) as is (1)\n            # Input time dim is only 7, so we can't afford to shrink it.\n            conv_layers.append(nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)))\n            \n            in_channels = filters\n        \n        self.cnn_stack = nn.Sequential(*conv_layers)\n        self.cnn_dropout = nn.Dropout(Tconfig.dropout_rate)\n        \n        # Calculate sizes\n        num_pools = len(Tconfig.conv_filters)\n        \n        # Frequency is pooled 3 times (div by 2^3)\n        self.post_cnn_freq = freq_bins // (2**num_pools)\n        \n        # FIX: Time is NOT pooled anymore\n        self.post_cnn_time = time_bins \n        \n        rnn_input_size = in_channels * self.post_cnn_freq\n        \n        # 2. RNN: BiLSTM\n        self.bilstm1 = nn.LSTM(\n            input_size=rnn_input_size, \n            hidden_size=Tconfig.lstm_units,\n            num_layers=1, \n            bidirectional=True, \n            batch_first=True, \n            dropout=Tconfig.dropout_rate if Tconfig.dropout_rate > 0 else 0\n        )\n        \n        self.bilstm2 = nn.LSTM(\n            input_size=Tconfig.lstm_units * 2,\n            hidden_size=Tconfig.lstm_units // 2,\n            num_layers=1, \n            bidirectional=True, \n            batch_first=True,\n        )\n\n        dense_input_size = (Tconfig.lstm_units // 2) * 2\n        self.dense_stack = nn.Sequential(\n            nn.Dropout(Tconfig.dropout_rate),\n            nn.Linear(dense_input_size, 256),\n            nn.ReLU(),\n            nn.Dropout(Tconfig.dropout_rate),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # 1. CNN\n        x = self.cnn_stack(x)\n        x = self.cnn_dropout(x)\n        \n        # 2. Permute and Flatten \n        # Output is (Batch, Channels, Freq, Time)\n        # We want (Batch, Time, Freq, Channels) -> (Batch, Time, Features)\n        x = x.permute(0, 3, 2, 1) \n        B, T, F, C = x.shape\n        \n        x = x.reshape(B, T, F * C) \n        \n        # 3. RNN\n        x, _ = self.bilstm1(x) \n        x, (h_n, c_n) = self.bilstm2(x) \n        \n        x = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=1)\n        x = self.dense_stack(x)\n        return x\n\nmodel = CNNBiLSTM(freq_bins, time_bins, num_ch, num_classes, Tconfig).to(DEVICE)\nprint(f\"Model created successfully. Output classes: {num_classes}\")\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"Total trainable parameters: {count_parameters(model):,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:54:50.865438Z","iopub.execute_input":"2025-12-16T05:54:50.865793Z","iopub.status.idle":"2025-12-16T05:54:50.939553Z","shell.execute_reply.started":"2025-12-16T05:54:50.865771Z","shell.execute_reply":"2025-12-16T05:54:50.938809Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Training & Validation Loop\n\nWe set up the training infrastructure:\n* **Optimizer**: Adam with learning rate scheduling (`ReduceLROnPlateau`).\n* **Loss Function**: CrossEntropyLoss for multi-class classification.\n* **Checkpointing**: The model is saved (`best_model.pth`) only when validation accuracy improves.\n* **Early Stopping**: Training halts if no improvement is seen for a set number of epochs.","metadata":{}},{"cell_type":"code","source":"#Setup Optimizer, Loss, and Scheduler\noptimizer = optim.Adam(model.parameters(), lr=Tconfig.learning_rate, weight_decay=1e-4)\ncriterion = nn.CrossEntropyLoss() \nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, \n    mode='max',\n    factor=0.5, \n    patience=2, \n    min_lr=1e-5, \n    verbose=True\n)\n\n#Checkpoint and History Setup\ncheckpoint_path = Tconfig.models_root / \"best_model.pth\"\nfinal_model_path = Tconfig.models_root / \"final_model.pth\"\nlog_path = Tconfig.reports_root / \"training_history.json\"\n\nhistory = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': [], 'top5_accuracy': [], 'lr': []}\nbest_val_accuracy = 0.0\npatience_counter = 0\n\n#Training and Evaluation Functions\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, labels in dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\ndef evaluate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    top5_correct = 0\n    \n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * inputs.size(0)\n            \n            # Accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            # Top-5 Accuracy\n            # Use min(5, num_classes) to prevent errors if you have < 5 classes\n            k = min(5, outputs.size(1))\n            _, topk_preds = outputs.topk(k, 1, True, True)\n            top5_correct += torch.sum(topk_preds.eq(labels.view(-1, 1))).item()\n            \n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct / total\n    epoch_top5_acc = top5_correct / total\n    \n    return epoch_loss, epoch_acc, epoch_top5_acc\n\n\nprint(\"Starting training...\")\nfor epoch in range(1, Tconfig.epochs + 1):\n    \n    # Training step\n    train_loss, train_acc = train_epoch(model, dtrain, criterion, optimizer, DEVICE)\n    \n    # Validation step\n    val_loss, val_acc, val_top5_acc = evaluate_epoch(model, dval, criterion, DEVICE)\n    \n    # Update History\n    history['loss'].append(train_loss)\n    history['accuracy'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_accuracy'].append(val_acc)\n    history['top5_accuracy'].append(val_top5_acc)\n    history['lr'].append(optimizer.param_groups[0]['lr'])\n    \n    print(f\"Epoch {epoch}/{Tconfig.epochs} | LR: {history['lr'][-1]:.6f}\")\n    print(f\"  Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n    print(f\"  Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Top5 Acc: {val_top5_acc:.4f}\")\n\n    # Learning Rate Scheduler (based on val_acc)\n    scheduler.step(val_acc) \n\n    # Model Checkpointing\n    if val_acc > best_val_accuracy:\n        best_val_accuracy = val_acc\n        patience_counter = 0\n        print(f\"  --> Improvement! Saving model to {checkpoint_path}\")\n        torch.save(model.state_dict(), checkpoint_path)\n    else:\n        patience_counter += 1\n        \n    # Early Stopping\n    if patience_counter >= Tconfig.patience:\n        print(f\"\\nEarly stopping triggered after {patience_counter} epochs without improvement.\")\n        break\n\n# Save final model state\ntorch.save(model.state_dict(), final_model_path)\n\n# Save history\nwith open(log_path, \"w\") as fp:\n    dump_history = {k: [float(x) for x in v] for k, v in history.items()}\n    json.dump(dump_history, fp, indent=2)\n    \nprint(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T05:54:50.940559Z","iopub.execute_input":"2025-12-16T05:54:50.941000Z","iopub.status.idle":"2025-12-16T06:01:05.988925Z","shell.execute_reply.started":"2025-12-16T05:54:50.940970Z","shell.execute_reply":"2025-12-16T06:01:05.987764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_history(history: dict) -> None:\n    history_df = pd.DataFrame(history)\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Loss Plot\n    if \"loss\" in history_df.columns:\n        history_df[[\"loss\", \"val_loss\"]].plot(ax=axes[0])\n        axes[0].set_title(\"Loss Curve\")\n        axes[0].set_xlabel(\"Epoch\")\n        axes[0].set_ylabel(\"Cross Entropy Loss\")\n        axes[0].grid(True)\n\n    # Accuracy Plot \n    if \"accuracy\" in history_df.columns:\n        history_df[[\"accuracy\", \"val_accuracy\"]].plot(ax=axes[1])\n        axes[1].set_title(\"Accuracy Curve\")\n        axes[1].set_xlabel(\"Epoch\")\n        axes[1].set_ylabel(\"Accuracy\")\n        axes[1].grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n\nplot_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:01:05.989969Z","iopub.execute_input":"2025-12-16T06:01:05.990460Z","iopub.status.idle":"2025-12-16T06:01:06.890494Z","shell.execute_reply.started":"2025-12-16T06:01:05.990422Z","shell.execute_reply":"2025-12-16T06:01:06.889684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10. Performance Metrics\n\nWe run inference on the held-out **Test Set** (Session B) and generate a classification report. This includes:\n* **Precision/Recall/F1-Score**: To evaluate performance per person.\n* **Accuracy**: Overall system performance.","metadata":{}},{"cell_type":"code","source":"import json\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import classification_report\n\n# Instantiate a new model to ensure we are testing the clean \"best\" version\nbest_model = CNNBiLSTM(freq_bins, time_bins, num_ch, num_classes, Tconfig).to(DEVICE)\n\nif checkpoint_path.exists():\n    print(f\"Loading best model from {checkpoint_path}\")\n    best_model.load_state_dict(torch.load(checkpoint_path))\nelse:\n    print(\"Checkpoint not found, using current model state.\")\n\nbest_model.eval()\n\ndef predict_and_evaluate(model, dataloader, criterion, device):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item() * inputs.size(0)\n\n            # Metrics\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(outputs.cpu().numpy())\n\n    test_loss = total_loss / total\n    test_accuracy = correct / total\n    \n    test_results = {\n        \"loss\": test_loss,\n        \"accuracy\": test_accuracy,\n    }\n    \n    # Convert predictions to class indices (labels)\n    y_pred_probs = np.array(all_preds)\n    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n    \n    return test_results, np.array(all_labels), y_pred_labels\n\n# Run Evaluation on Test Set\ncriterion = nn.CrossEntropyLoss()\ntest_results, y_true_labels, y_pred_labels = predict_and_evaluate(best_model, dtest, criterion, DEVICE)\n\nprint(f\"Test Results: {test_results}\")\n\nif 'label_mapping' not in locals():\n    label_mapping = {i: f\"Subject_{i}\" for i in range(num_classes)}\n    print(f\"Created generic label mapping for {num_classes} classes.\")\n\n# Classification Report\n# Ensure keys are sorted integers so they match the model's output indices 0..N\nsorted_keys = sorted([int(k) for k in label_mapping.keys()])\ntarget_names = [str(label_mapping[k]) for k in sorted_keys]\n\n# Print Text Report\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(\n    y_true_labels,\n    y_pred_labels,\n    labels=sorted_keys,\n    target_names=target_names,\n    zero_division=0\n))\n\n# Save metrics to JSON\nmetrics_path = Tconfig.reports_root / \"test_metrics.json\"\nwith open(metrics_path, \"w\") as fp:\n    json.dump({\n        \"test_results\": test_results, \n        \"classification_report\": classification_report(\n            y_true_labels, y_pred_labels, labels=sorted_keys, \n            target_names=target_names, output_dict=True, zero_division=0\n        )\n    }, fp, indent=2)\n\nprint(f\"Metrics saved to {metrics_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:05:18.562878Z","iopub.execute_input":"2025-12-16T06:05:18.563395Z","iopub.status.idle":"2025-12-16T06:05:28.003722Z","shell.execute_reply.started":"2025-12-16T06:05:18.563356Z","shell.execute_reply":"2025-12-16T06:05:28.002865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n# 1. Get Predictions and Probabilities\ndef get_predictions(model, dataloader, device):\n    model.eval()\n    all_probs = []\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            probs = torch.softmax(outputs, dim=1)  # Convert logits to probs\n            preds = torch.argmax(probs, dim=1)     # Get predicted class\n            \n            all_probs.extend(probs.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.numpy())\n            \n    return np.array(all_labels), np.array(all_preds), np.array(all_probs)\n\ny_true, y_pred, y_probs = get_predictions(best_model, dtest, DEVICE)\n\n# 2. Calculate Top-5 Accuracy\n# Note: If you have < 5 classes, Top-5 Acc is always 1.0\nk = min(5, num_classes)\ntop_k_preds = np.argsort(y_probs, axis=1)[:, -k:]\ntop_5_acc = np.mean([1 if true_label in pred_row else 0 \n                     for true_label, pred_row in zip(y_true, top_k_preds)])\n\n# 3. Overall Metrics\ntest_acc = accuracy_score(y_true, y_pred)\nweighted_f1 = f1_score(y_true, y_pred, average='weighted')\n\nprint(f\"Test Accuracy:  {test_acc:.4f}\")\nprint(f\"Weighted F1:    {weighted_f1:.4f}\")\nprint(f\"Top-{k} Accuracy: {top_5_acc:.4f}\")\n\n# 4. Per-Subject Accuracy\n# Ensure we use the correct label keys. If label_mapping isn't available, we create a dummy one.\ntry:\n    # If label_mapping is a dict of {int: str}\n    labels_list = sorted(label_mapping.keys())\n    subject_names = [label_mapping[i] for i in labels_list]\nexcept (NameError, AttributeError, KeyError):\n    # Fallback if label_mapping missing\n    labels_list = sorted(list(set(y_true) | set(y_pred)))\n    subject_names = [f\"Subject {i}\" for i in labels_list]\n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred, labels=labels_list)\n\n# Normalize CM to get recall (accuracy) per class\nwith np.errstate(divide='ignore', invalid='ignore'):\n    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n# --- FIX: Replace NaNs (0/0 division) with 0.0 ---\ncm_norm = np.nan_to_num(cm_norm)\n\n# Create DataFrame\nper_subject_df = pd.DataFrame({\n    \"subject\": subject_names,\n    \"accuracy\": np.diag(cm_norm),  # Diagonal elements are correct predictions\n    \"support\": cm.sum(axis=1)      # Total samples per class\n})\n\n# Sort by accuracy\nper_subject_df = per_subject_df.sort_values(\"accuracy\", ascending=False)\n\nprint(\"\\nTop 5 Performing Subjects:\")\nprint(per_subject_df.head(5))\n\nprint(\"\\nWorst 5 Performing Subjects:\")\nprint(per_subject_df.tail(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:06:06.369651Z","iopub.execute_input":"2025-12-16T06:06:06.370718Z","iopub.status.idle":"2025-12-16T06:06:16.236268Z","shell.execute_reply.started":"2025-12-16T06:06:06.370681Z","shell.execute_reply":"2025-12-16T06:06:16.235340Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11. Confusion Matrix\n\nThe confusion matrix helps identify specific misclassifications.\n* **Diagonal**: Correct predictions.\n* **Off-diagonal**: Errors (e.g., identifying Person A as Person B).","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 12))\nsns.heatmap(cm_norm, annot=False, fmt='.2f', cmap='Blues',\n            xticklabels=[label_mapping[i] for i in sorted(label_mapping.keys())],\n            yticklabels=[label_mapping[i] for i in sorted(label_mapping.keys())])\nplt.title(\"Normalized Confusion Matrix (Recall)\")\nplt.xlabel(\"Predicted Subject\")\nplt.ylabel(\"True Subject\")\nplt.show()\n\nplot_df = per_subject_df[per_subject_df[\"support\"] > 0]\n\nn_plot = min(5, len(plot_df))\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n\n# Top 5\nplot_df.head(n_plot).plot.bar(x=\"subject\", y=\"accuracy\", ax=axes[0], color=\"#1f77b4\", legend=False)\naxes[0].set_title(f\"Top {n_plot} Subjects\")\naxes[0].set_ylabel(\"Accuracy\")\naxes[0].set_ylim(0, 1.05)\naxes[0].grid(axis='y', alpha=0.3)\n\n# Bottom 5 (Reversed for visual consistency)\nplot_df.tail(n_plot).sort_values(\"accuracy\", ascending=True).plot.bar(x=\"subject\", y=\"accuracy\", ax=axes[1], color=\"#d62728\", legend=False)\naxes[1].set_title(f\"Lowest {n_plot} Subjects\")\naxes[1].grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:06:53.003613Z","iopub.execute_input":"2025-12-16T06:06:53.004185Z","iopub.status.idle":"2025-12-16T06:06:53.779946Z","shell.execute_reply.started":"2025-12-16T06:06:53.004160Z","shell.execute_reply":"2025-12-16T06:06:53.779150Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12. Latent Space Visualization (t-SNE)\n\nTo understand *what* the model has learned, we extract the feature embeddings (the output of the LSTM before the final classification layer). \nWe use **t-SNE** to project these high-dimensional vectors into 2D space. well-separated clusters indicate that the model has learned distinct features for each person.","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport torch\n\n# 1. Setup Hook to extract embeddings\nembeddings_list = []\ndef hook_fn(module, input, output):\n    # Flatten the input to the final layer if it isn't already\n    embeddings_list.append(input[0].detach().cpu().numpy())\n\n# Attach hook to the final layer (usually named 'fc' or similar in your architecture)\nfinal_layer = list(best_model.children())[-1]\nhandle = final_layer.register_forward_hook(hook_fn)\n\n# 2. Run a larger batch to ensure we catch enough data for our target subjects\n# We scan more data initially (e.g. 3000) to find enough samples for specific subjects\nscan_limit = 3000\nextracted_labels = []\ncount = 0\n\nbest_model.eval()\nwith torch.no_grad():\n    for inputs, labels in dtest:\n        inputs = inputs.to(DEVICE)\n        _ = best_model(inputs) # Forward pass triggers the hook\n        \n        extracted_labels.extend(labels.numpy())\n        count += inputs.size(0)\n        if count >= scan_limit:\n            break\n\n# Remove hook\nhandle.remove()\n\n# Concatenate all batches\nX_full = np.concatenate(embeddings_list, axis=0)[:count]\ny_full = np.array(extracted_labels)[:count]\n\n# Flatten if necessary\nif len(X_full.shape) > 2:\n    X_full = X_full.reshape(X_full.shape[0], -1)\n\n# --- FILTER FOR 5 SUBJECTS ---\n# Pick 5 unique subjects present in the data\nunique_subjects = np.unique(y_full)\nif len(unique_subjects) > 5:\n    target_subjects = unique_subjects[:5] # Pick the first 5 found\nelse:\n    target_subjects = unique_subjects\n\nprint(f\"Visualizing Subjects: {target_subjects}\")\n\n# Create a mask to select only these subjects\nmask = np.isin(y_full, target_subjects)\nX_embedded = X_full[mask]\ny_embedded = y_full[mask]\n\nprint(f\"Embeddings shape (filtered): {X_embedded.shape}\")\n\n# 3. Compute t-SNE\nprint(\"Running t-SNE... this might take a moment.\")\ntsne = TSNE(n_components=2, perplexity=30, init='pca', random_state=42)\ntsne_coords = tsne.fit_transform(X_embedded)\n\n# 4. Plot t-SNE\nplt.figure(figsize=(10, 8))\n\ncmap = matplotlib.colormaps['tab10'] \ncolors = cmap.resampled(len(target_subjects))\n\nfor i, subject_id in enumerate(target_subjects):\n    # Find points belonging to this subject\n    idxs = (y_embedded == subject_id)\n    \n    # Get label name if available, else use ID\n    try:\n        label_name = label_mapping[subject_id]\n    except:\n        label_name = f\"Subject {subject_id}\"\n        \n    plt.scatter(tsne_coords[idxs, 0], tsne_coords[idxs, 1], \n                label=label_name, alpha=0.7, s=20)\n\nplt.legend(title=\"Subject ID\")\nplt.title(f\"t-SNE Visualization (Top {len(target_subjects)} Subjects)\")\nplt.xlabel(\"t-SNE 1\")\nplt.ylabel(\"t-SNE 2\")\nplt.grid(True, alpha=0.3)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:12:01.466373Z","iopub.execute_input":"2025-12-16T06:12:01.466793Z","iopub.status.idle":"2025-12-16T06:12:17.681700Z","shell.execute_reply.started":"2025-12-16T06:12:01.466761Z","shell.execute_reply":"2025-12-16T06:12:17.680844Z"}},"outputs":[],"execution_count":null}]}